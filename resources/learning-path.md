# Learning Path

## A Structured Journey from Beginner to Expert

This guide provides a progression for developing AI skills. Whether you're just starting or looking to advance, find your current level and follow the path forward.

---

## The Progression

```
BEGINNER        PRACTITIONER        ADVANCED        EXPERT
    |                |                  |              |
    V                V                  V              V
Core concepts -> Daily usage -> Deep knowledge -> Teaching others
Basic prompts -> Workflows   -> Custom systems -> Novel approaches
Single model  -> Multi-model -> Local + Cloud  -> Full ecosystem
```

---

## Stage 1: Beginner

**Goal:** Understand what AI models are and how to use them effectively for basic tasks.

### Learn

1. **Core concepts** (1-2 hours)
   - Read [Getting Started](../guides/getting-started.md)
   - Understand what tokens and context windows are
   - Learn the basics of prompting

2. **First experiments** (2-3 hours)
   - Sign up for Claude or ChatGPT
   - Try 20+ varied prompts
   - Notice what works and what doesn't

3. **Structured prompting** (2-3 hours)
   - Read [Prompt Engineering 101](../guides/prompt-engineering-101.md)
   - Practice each technique
   - Build intuition for prompt structure

### Practice Projects

- [ ] Use AI to explain a complex concept you're learning
- [ ] Get help debugging a piece of code
- [ ] Generate documentation for existing code
- [ ] Summarize a long article or paper
- [ ] Write an email with AI assistance

### Milestones

You've completed this stage when you can:
- Write prompts that consistently get useful results
- Understand why some prompts work better than others
- Use AI assistance for daily tasks effectively

### Resources

- [Anthropic Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- This repository's [Guides](../guides/) section

---

## Stage 2: Practitioner

**Goal:** Integrate AI into your regular workflow and understand model differences.

### Learn

1. **Model landscape** (2-3 hours)
   - Read [Choosing the Right Model](../guides/choosing-the-right-model.md)
   - Understand trade-offs between models
   - Learn when to use which model

2. **Agent tools** (4-6 hours)
   - Set up [Cursor](../agents/cursor/setup.md) or [Aider](../agents/aider/overview.md)
   - Learn the workflow patterns
   - Practice daily coding with AI assistance

3. **Advanced prompting** (3-4 hours)
   - Study [Advanced Prompting](../guides/advanced-prompting.md)
   - Practice chain-of-thought and meta-prompting
   - Develop prompt templates for your common tasks

### Practice Projects

- [ ] Complete a small feature entirely with AI assistance
- [ ] Build a personal prompt library
- [ ] Configure your AI coding assistant optimally
- [ ] Compare outputs from different models on the same task
- [ ] Refactor a legacy code section with AI help

### Milestones

You've completed this stage when you can:
- Work significantly faster with AI assistance
- Choose appropriate models for different tasks
- Have established workflows with AI tools
- Debug effectively using AI
- Create reliable, reusable prompts

### Resources

- [Claude Model Docs](../models/claude/)
- [GPT Model Docs](../models/gpt/)
- [Cursor Workflows](../agents/cursor/workflows.md)
- [Prompt Library](../prompts/)

---

## Stage 3: Advanced

**Goal:** Deep understanding of AI systems and ability to build custom solutions.

### Learn

1. **Local models** (4-6 hours)
   - Read [Local Models](../models/local-models/overview.md)
   - Set up Ollama and run models locally
   - Understand quantization and hardware requirements

2. **API integration** (6-8 hours)
   - Study [API Quick Reference](../references/api-quick-reference.md)
   - Build a simple application using LLM APIs
   - Implement proper error handling and retry logic

3. **System design** (ongoing)
   - Learn about RAG (Retrieval-Augmented Generation)
   - Understand embedding and vector databases
   - Study agent architectures

### Practice Projects

- [ ] Build a custom CLI tool using LLM APIs
- [ ] Create a RAG system for your documentation
- [ ] Implement a multi-step agent for a specific task
- [ ] Fine-tune a small model on domain-specific data
- [ ] Build a cost-optimized system using model routing

### Milestones

You've completed this stage when you can:
- Build custom applications using LLM APIs
- Run and evaluate local models
- Design systems that use AI effectively
- Make informed decisions about build vs. buy
- Optimize for cost and quality simultaneously

### Resources

- [LangChain Documentation](https://python.langchain.com/)
- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [Hugging Face Course](https://huggingface.co/learn)
- [Open Source Models](../models/llama/)

---

## Stage 4: Expert

**Goal:** Contribute to the field, build novel solutions, and help others learn.

### Learn

1. **Research literacy** (ongoing)
   - Follow arXiv for relevant papers
   - Understand training and fine-tuning at a deeper level
   - Stay current with model architectures

2. **Production systems** (project-based)
   - Build and maintain production AI systems
   - Handle scale, reliability, and cost challenges
   - Develop monitoring and evaluation frameworks

3. **Teaching and sharing** (ongoing)
   - Document your learnings
   - Contribute to communities
   - Mentor others

### Practice Projects

- [ ] Contribute to an open-source AI project
- [ ] Write a technical blog post about a discovery
- [ ] Build a novel application that pushes boundaries
- [ ] Fine-tune and release a model
- [ ] Create educational content

### Milestones

You're at this stage when you:
- Can evaluate new AI developments critically
- Build systems others use as references
- Contribute back to the community meaningfully
- Help others progress through earlier stages
- Have opinions that are informed by deep experience

### Resources

- arXiv daily readings
- Conference proceedings (NeurIPS, ICML, ACL)
- Direct engagement with research communities
- Building in public

---

## Continuous Learning Habits

### Daily (5-10 minutes)

- Check one AI news source
- Use AI tools in your work
- Note what works/doesn't

### Weekly (1-2 hours)

- Read one in-depth article or paper
- Try one new technique or tool
- Refine your prompt library

### Monthly (4-8 hours)

- Evaluate new models or tools
- Update your workflows based on learnings
- Share something you've learned

### Quarterly (1-2 days)

- Assess your skill progression
- Set learning goals for next quarter
- Deep dive into one new area

---

## Learning Principles

### Active over Passive

Reading about prompting is not the same as prompting. Every concept requires practice to become skill.

### Depth over Breadth (Initially)

Master one model and one workflow before exploring alternatives. Depth creates foundations for breadth.

### Build to Learn

Projects teach more than tutorials. Build something real, even if small.

### Share to Solidify

Teaching forces understanding. Write about what you learn, even if just for yourself.

### Embrace Change

The field evolves rapidly. Stay curious, be willing to update beliefs, and don't get too attached to specific tools.

---

## Tracking Progress

### Skills Checklist

**Fundamentals:**
- [ ] Can write effective prompts consistently
- [ ] Understand tokens and context windows
- [ ] Know when to use different models

**Daily Usage:**
- [ ] AI-assisted coding is natural
- [ ] Have established workflows
- [ ] Can troubleshoot common issues

**Technical Depth:**
- [ ] Can build applications with LLM APIs
- [ ] Understand RAG and embeddings
- [ ] Can run and evaluate local models

**Advanced:**
- [ ] Can design AI-integrated systems
- [ ] Understand trade-offs at a deep level
- [ ] Contribute to the field in some way

---

*Learning is a journey without a destination. The goal isn't to "finish" but to continually grow. Find your current edge and push it forward, one step at a time.*

